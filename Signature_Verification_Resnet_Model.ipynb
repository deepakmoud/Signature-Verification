{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Signature Verification Resnet_Model",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNCrcH3t5n5gR3K+zH4Lw/U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepakmoud/Signature-Verification/blob/master/Signature_Verification_Resnet_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpKenELA4wJM",
        "colab_type": "code",
        "outputId": "23776de7-6726-445d-8474-bb3586116c14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i1xxXh95Uh9",
        "colab_type": "code",
        "outputId": "a52b3461-7925-44ab-e5c6-b4e5ba807461",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/My Drive/model_resnet_signature_verification.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dekV0Yfs-a3O",
        "colab_type": "code",
        "outputId": "8ea721e4-66f2-4fe9-a648-112642366d00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from numpy import asarray\n",
        "from numpy import save\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import numpy as np\n",
        "folder = '/content/drive/My Drive/Dataset1/training_set/'\n",
        "photos, labels = list(), list()\n",
        "for r, d, f in os.walk(folder):\n",
        "    for file in f:\n",
        "        if \".png\" in file:\n",
        "          if(os.path.join(r, file)=='/content/drive/My Drive/Dataset1/training_set/genuine/{}'.format(file)):\n",
        "            output=1\n",
        "          elif(os.path.join(r, file)=='/content/drive/My Drive/Dataset1/training_set/forged/{}'.format(file)):\n",
        "            output=0\n",
        "        labels.append(output)\n",
        "y_train=np.array(labels)\n",
        "print(os.path.join(r, file))\n",
        "print(y_train.shape)\n",
        "y_train=np.expand_dims(y_train, axis=1)\n",
        "print(y_train)\n",
        "\n",
        "print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Dataset1/training_set/genuine/006_01.PNG\n",
            "(2112,)\n",
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "(2112, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4A_awZbvPtK",
        "colab_type": "code",
        "outputId": "5c660539-1bbb-4618-8a64-2190921e309e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from numpy import asarray\n",
        "from numpy import save\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import numpy as np\n",
        "folder = '/content/drive/My Drive/Dataset1/testing_set/'\n",
        "photos, labels = list(), list()\n",
        "for r, d, f in os.walk(folder):\n",
        "    for file in f:\n",
        "        if \".png\" in file:\n",
        "          if(os.path.join(r, file)=='/content/drive/My Drive/Dataset1/testing_set/genuine/{}'.format(file)):\n",
        "            output=1\n",
        "          elif(os.path.join(r, file)=='/content/drive/My Drive/Dataset1/testing_set/forged/{}'.format(file)):\n",
        "            output=0\n",
        "        labels.append(output)\n",
        "y_test=np.array(labels)\n",
        "print(os.path.join(r, file))\n",
        "print(y_test.shape)\n",
        "y_test=np.expand_dims(y_test, axis=1)\n",
        "\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Dataset1/testing_set/genuine/NFI-03001030.PNG\n",
            "(558,)\n",
            "(558, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB4JkCUGBVXx",
        "colab_type": "code",
        "outputId": "34ea3edb-1159-45bb-bbd6-63b875686762",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_data_dir ='/content/drive/My Drive/Dataset1/training_set'\n",
        "val_data_dir ='/content/drive/My Drive/Dataset1/testing_set'\n",
        "img_width, img_height = 128, 128\n",
        "print(\"Input parameters are assigned\")\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_width, img_height), \n",
        "                                                    batch_size=32,shuffle=False, class_mode='binary')\n",
        "validation_generator = test_datagen.flow_from_directory(val_data_dir, target_size=(img_width, img_height), \n",
        "                                                    batch_size=32,shuffle=False,class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input parameters are assigned\n",
            "Found 2112 images belonging to 2 classes.\n",
            "Found 544 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qdiZxOSAIov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "layer_name= 'classification_layer'\n",
        "intermediate_layer_model = Model(inputs=model.input,\n",
        "                                 outputs=model.get_layer(layer_name).output)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsEV6uSE4GJc",
        "colab_type": "code",
        "outputId": "2c90e434-4073-4867-e75d-86065e0d5602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "intermediate_layer_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(\"Model is Complied\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model is Complied\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_-hd5V2vOSo",
        "colab_type": "code",
        "outputId": "c5729b78-8e81-43c1-ada7-ec5e7ea16e52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "X_train = np.array(intermediate_output)\n",
        "print(X_train)\n",
        "print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.01735571 0.         0.         ... 0.01666759 0.         0.54134977]\n",
            " [0.38565636 0.         0.         ... 0.28582665 0.         0.66373926]\n",
            " [0.         0.         0.         ... 0.55383164 0.         1.1099485 ]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.45720598 0.         1.1208855 ]\n",
            " [0.         0.         0.         ... 0.6634016  0.         1.3446887 ]\n",
            " [0.         0.         0.         ... 0.6021743  0.         0.7941411 ]]\n",
            "(2117, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjuqUDiYGUlX",
        "colab_type": "code",
        "outputId": "44256f5b-eb13-4eac-e963-2bc2fbc12f53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "intermediate_layer_model.save(\"/content/drive/My Drive/intermediate_layer_model_Resnet_signature_verification.h5\")\n",
        "intermediate_layer_model.summary()\n",
        "\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet152v2_input (InputLaye (None, 128, 128, 3)       0         \n",
            "_________________________________________________________________\n",
            "resnet152v2 (Model)          (None, 4, 4, 2048)        58331648  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 128)               4194432   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "classification_layer (Dense) (None, 64)                8256      \n",
            "=================================================================\n",
            "Total params: 62,550,848\n",
            "Trainable params: 4,219,200\n",
            "Non-trainable params: 58,331,648\n",
            "_________________________________________________________________\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLopVWkDHrdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model(\"/content/drive/My Drive/intermediate_layer_model_Resnet_signature_verification.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCxYYbu4rBSB",
        "colab_type": "code",
        "outputId": "bdae2df9-4c5b-44c1-b5c5-16caa00a66eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "intermediate_output = model.predict(train_generator)\n",
        "X_train = np.array(intermediate_output)\n",
        "print(X_train)\n",
        "print(X_train.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.04080538 0.         0.         ... 0.24520843 0.         0.2870128 ]\n",
            " [0.18529175 0.         0.         ... 0.13276514 0.         0.7961746 ]\n",
            " [0.83705163 0.         0.         ... 0.15483057 0.         0.12253357]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.13174962 0.7788184  0.7281856 ]\n",
            " [0.         0.         0.         ... 0.04705884 0.         0.4242718 ]\n",
            " [0.         0.         0.         ... 0.01643293 0.         0.6036549 ]]\n",
            "(2112, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VTyviS-I-fn",
        "colab_type": "code",
        "outputId": "d7656fbb-3060-4e6f-ce0b-953ab4c91223",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "\n",
        "intermediate_output_test = model.predict(validation_generator)\n",
        "X_test = np.array(intermediate_output_test)\n",
        "print(X_test)\n",
        "print(X_test.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.47755185 ... 0.         0.         1.2937185 ]\n",
            " [0.         0.         0.         ... 0.49642214 0.         0.87089944]\n",
            " [0.         0.         0.         ... 0.7423522  0.         1.5141789 ]\n",
            " ...\n",
            " [0.22510923 0.         0.         ... 0.         0.         0.7763593 ]\n",
            " [0.4470289  0.         0.         ... 0.         0.         0.7778905 ]\n",
            " [0.         0.         0.         ... 0.2777875  0.         2.3784344 ]]\n",
            "(558, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZS_DeHCswey",
        "colab_type": "code",
        "outputId": "298d6228-b641-4114-ac8a-55baaef39753",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Pass data through convolutional base\n",
        " import numpy as np\n",
        " batch_size=32\n",
        " sample_count=2112\n",
        " features = np.zeros(shape=(2112, 64))  # Must be equal to the output of the convolutional base\n",
        " labels = np.zeros(shape=(2112))\n",
        " i = 0\n",
        " for inputs_batch, labels_batch in train_generator:\n",
        "   features_batch = model.predict(inputs_batch)\n",
        "   features[i * batch_size: (i + 1) * batch_size] = features_batch\n",
        "   labels[i * batch_size: (i + 1) * batch_size] = labels_batch\n",
        "   i += 1\n",
        "   if i*batch_size  >= sample_count:\n",
        "     break\n",
        " print(labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2112,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWqz1QYVUjXI",
        "colab_type": "code",
        "outputId": "8ffe56d9-e2f2-40e0-9d02-fecfac7c2284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        " \n",
        "\n",
        "\n",
        "features_train=features\n",
        "print(features_train.shape)\n",
        "labels_train=np.expand_dims(labels, axis=1)\n",
        "print(labels_train.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2112, 64)\n",
            "(2112, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsZtf8oxHihF",
        "colab_type": "code",
        "outputId": "f6afe394-17b2-43c2-9be8-c82a6fc180b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "# Pass data through convolutional base\n",
        " import numpy as np\n",
        " batch_size=32\n",
        " sample_count=544\n",
        " features_test = np.zeros(shape=(544, 64))  # Must be equal to the output of the convolutional base\n",
        " labels_test = np.zeros(shape=(544))\n",
        " i = 0\n",
        " for inputs_batch, labels_batch in validation_generator:\n",
        "   features_batch = model.predict(inputs_batch)\n",
        "   features_test[i * batch_size: (i + 1) * batch_size] = features_batch\n",
        "   labels_test[i * batch_size: (i + 1) * batch_size] = labels_batch\n",
        "   i += 1\n",
        "   if i*batch_size  >= sample_count:\n",
        "     break\n",
        " print(labels_test.shape)\n",
        " print(features_test.shape)\n",
        " print(labels_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(544,)\n",
            "(544, 64)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkUhJ_jzJ65l",
        "colab_type": "code",
        "outputId": "2e9b4f06-92ea-46fe-d290-2fc38549c51b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "print(features_test.shape)\n",
        "labels_test=np.expand_dims(labels_test, axis=1)\n",
        "print(labels_test.shape)\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(544, 64)\n",
            "(544, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIzdpEVC6dFI",
        "colab_type": "code",
        "outputId": "63d36574-3d7e-470d-fe2a-dcc152b1befa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# SVM\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(features_train)\n",
        "X_test = sc.transform(features_test)\n",
        "\n",
        "# Fitting SVM to the Training set\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'linear', random_state = 0)\n",
        "classifier.fit(X_train,labels_train.ravel())\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(labels_test, y_pred)\n",
        "print(cm)\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(labels_test, y_pred))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[172  96]\n",
            " [ 99 177]]\n",
            "0.6415441176470589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxs_ouDb9dmm",
        "colab_type": "code",
        "outputId": "c21e12a7-3888-4d33-f7a1-01f32c1b4bb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\n",
        "# Kernel SVM\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(features_train)\n",
        "X_test = sc.transform(features_test)\n",
        "\n",
        "# Fitting KernelSVM to the Training set\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
        "classifier.fit(X_train, labels_train.ravel())\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(labels_test, y_pred)\n",
        "print(cm)\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(labels_test, y_pred))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[173  95]\n",
            " [ 87 189]]\n",
            "0.6654411764705882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvTkxl8x9dqU",
        "colab_type": "code",
        "outputId": "7c77301e-bc6c-4b5a-e189-fe8389da6a90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\n",
        "\n",
        "# Random Forest\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(features_train)\n",
        "X_test = sc.transform(features_test)\n",
        "\n",
        "# Fitting KernelSVM to the Training set\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, labels_train.ravel())\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(labels_test, y_pred)\n",
        "print(cm)\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(labels_test, y_pred))\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[191  77]\n",
            " [131 145]]\n",
            "0.6176470588235294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQR20j-F9dh7",
        "colab_type": "code",
        "outputId": "1eab60fd-4e43-4e5a-cbcb-cb3295cbbd05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\n",
        "# Decision Tree\n",
        "# Feature Scaling\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(features_train)\n",
        "X_test = sc.transform(features_test)\n",
        "\n",
        "# Fitting KernelSVM to the Training set\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, labels_train.ravel())\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(labels_test, y_pred)\n",
        "print(cm)\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(labels_test, y_pred))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[164 104]\n",
            " [120 156]]\n",
            "0.5882352941176471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1808468a-2d7e-4a3d-c47d-31f4e1246860",
        "id": "Od1aFp9qR26N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Naive Bayes\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(features_train)\n",
        "X_test = sc.transform(features_test)\n",
        "\n",
        "# Fitting KernelSVM to the Training set\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, labels_train.ravel())\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(labels_test, y_pred)\n",
        "print(cm)\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(labels_test, y_pred))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[250  18]\n",
            " [243  33]]\n",
            "0.5202205882352942\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvZfEySZ-tvc",
        "colab_type": "code",
        "outputId": "81e382cf-6fe5-4217-8d97-6b90c1ed9bc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(features_train)\n",
        "X_test = sc.transform(features_test)\n",
        "\n",
        "# Fitting KernelSVM to the Training set\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier =  KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
        "classifier.fit(X_train, labels_train.ravel())\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(labels_test, y_pred)\n",
        "print(cm)\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(labels_test, y_pred))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[146 122]\n",
            " [ 91 185]]\n",
            "0.6084558823529411\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_4sDpKi_D2I",
        "colab_type": "code",
        "outputId": "17849653-9f7f-4513-ba1b-3e703ae4b1e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(features_train)\n",
        "X_test = sc.transform(features_test)\n",
        "\n",
        "# Fitting KernelSVM to the Training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train, labels_train.ravel())\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(labels_test, y_pred)\n",
        "print(cm)\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(labels_test, y_pred))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[170  98]\n",
            " [ 98 178]]\n",
            "0.6397058823529411\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5NPetxF_j7a",
        "colab_type": "code",
        "outputId": "8e595e3a-08ec-4768-c686-4792436c9e7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/My Drive/model_resnet_signature_verification.h5')\n",
        "# Evaluate the model on the test data using `evaluate`\n",
        "print('\\n# Evaluate on test data')\n",
        "results = model.evaluate(validation_generator)\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# Evaluate on test data\n",
            "17/17 [==============================] - 39s 2s/step\n",
            "test loss, test acc: [1.0143539905548096, 0.5202205777168274]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}