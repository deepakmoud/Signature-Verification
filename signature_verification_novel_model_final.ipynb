{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": " signature verification novel model final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepakmoud/Signature-Verification/blob/master/signature_verification_novel_model_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VX9U2sdL_6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the Keras libraries and packages\n",
        "from keras.layers import Input, Flatten, Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Flatten, Dense\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.resnet_v2 import ResNet152V2\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from keras.applications.nasnet import NASNetLarge\n",
        "from keras.applications.nasnet import NASNetMobile\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Conv2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "img_width, img_height = 224, 224\n",
        "input_shape=(img_height,img_width,3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI6stXzxVEW3",
        "colab_type": "code",
        "outputId": "670f7800-88d9-427e-9b6c-e633333d3d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "pip install -U keras"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.3)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD5xdmxmL_7J",
        "colab_type": "code",
        "outputId": "0638fb6e-9e5d-48e3-9360-cff255070fdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64, (11, 11), input_shape=input_shape, padding='same',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size= (3, 3)))\n",
        "\n",
        "model.add(Conv2D(128, (7, 7), padding='same',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "model.add(Convolution2D(192, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "model.add(Convolution2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "model.add(Flatten())\n",
        "hidden_layer=model.add(Dense(128, activation='relu', name='hidden_layer'))\n",
        "classification_layer=model.add(Dense(64, activation='relu', name='classification_layer'))\n",
        "output_layer=model.add(Dense(1, activation='sigmoid', name='output_layer')) \n",
        "print(\"All layers top of pretrained layers are developed\")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All layers top of pretrained layers are developed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtMH9DEhL_7Q",
        "colab_type": "code",
        "outputId": "5d1c8c6f-f63e-4755-9554-ab0ab7f67ae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data_dir ='/content/drive/My Drive/Dataset1/training_set'\n",
        "val_data_dir ='/content/drive/My Drive/Dataset1/testing_set'\n",
        "nb_epochs = 35\n",
        "file_path='/content/drive/My Drive/Colab Notebooks/Signature verification scratch model/novel_model_weights.hdf5'\n",
        "print(\"Input parameters are assigned\")"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input parameters are assigned\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Olk9_b4L_7V",
        "colab_type": "code",
        "outputId": "c73aa445-c19e-48a9-d799-87aeb7516dc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(\"Model is Complied\")"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model is Complied\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noo6mamOTfZa",
        "colab_type": "code",
        "outputId": "148ddb6e-896e-41eb-f9e3-22020597209d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz3f4zudL_7c",
        "colab_type": "code",
        "outputId": "6e34d05e-ded8-483e-b791-b0da0352808e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Imaga data generation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_width, img_height), \n",
        "                                                    batch_size=32,shuffle=False, class_mode='binary')\n",
        "validation_generator = test_datagen.flow_from_directory(val_data_dir, target_size=(img_width, img_height), \n",
        "                                                    batch_size=32,shuffle=False,class_mode='binary')\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2112 images belonging to 2 classes.\n",
            "Found 544 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhasJCgnL_7g",
        "colab_type": "code",
        "outputId": "838115f9-21c2-4185-a6b6-507249e3300d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "callbacks = [ModelCheckpoint(file_path, monitor='val_acc', save_best_only=True)]\n",
        "\n",
        "history = model.fit_generator( train_generator, callbacks = callbacks, nb_epoch=nb_epochs, validation_data=validation_generator)\n",
        "\n",
        "print('Training Completed!')\n",
        "\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "66/66 [==============================] - 50s 755ms/step - loss: 1.1393 - accuracy: 0.4190 - val_loss: 1.5438 - val_accuracy: 0.4926\n",
            "Epoch 2/35\n",
            "66/66 [==============================] - 47s 713ms/step - loss: 0.7120 - accuracy: 0.4754 - val_loss: 0.9793 - val_accuracy: 0.4926\n",
            "Epoch 3/35\n",
            "66/66 [==============================] - 47s 716ms/step - loss: 0.7594 - accuracy: 0.5455 - val_loss: 0.6401 - val_accuracy: 0.5074\n",
            "Epoch 4/35\n",
            "66/66 [==============================] - 47s 716ms/step - loss: 0.7386 - accuracy: 0.3816 - val_loss: 0.6489 - val_accuracy: 0.4522\n",
            "Epoch 5/35\n",
            "66/66 [==============================] - 48s 721ms/step - loss: 0.7298 - accuracy: 0.4801 - val_loss: 0.4251 - val_accuracy: 0.5074\n",
            "Epoch 6/35\n",
            "66/66 [==============================] - 48s 720ms/step - loss: 0.7124 - accuracy: 0.5857 - val_loss: 0.0308 - val_accuracy: 0.5074\n",
            "Epoch 7/35\n",
            "66/66 [==============================] - 48s 728ms/step - loss: 0.7060 - accuracy: 0.4872 - val_loss: 1.0260 - val_accuracy: 0.4926\n",
            "Epoch 8/35\n",
            "66/66 [==============================] - 48s 724ms/step - loss: 0.7052 - accuracy: 0.4309 - val_loss: 0.7750 - val_accuracy: 0.4908\n",
            "Epoch 9/35\n",
            "66/66 [==============================] - 48s 725ms/step - loss: 0.6953 - accuracy: 0.5170 - val_loss: 0.6689 - val_accuracy: 0.5110\n",
            "Epoch 10/35\n",
            "66/66 [==============================] - 48s 723ms/step - loss: 0.6945 - accuracy: 0.5407 - val_loss: 0.6757 - val_accuracy: 0.5092\n",
            "Epoch 11/35\n",
            "66/66 [==============================] - 48s 728ms/step - loss: 0.6922 - accuracy: 0.5412 - val_loss: 6.8230 - val_accuracy: 0.4926\n",
            "Epoch 12/35\n",
            "66/66 [==============================] - 48s 732ms/step - loss: 0.6926 - accuracy: 0.5412 - val_loss: 1.9471 - val_accuracy: 0.4926\n",
            "Epoch 13/35\n",
            "66/66 [==============================] - 49s 740ms/step - loss: 0.6915 - accuracy: 0.5398 - val_loss: 0.8691 - val_accuracy: 0.4835\n",
            "Epoch 14/35\n",
            "66/66 [==============================] - 48s 731ms/step - loss: 0.6915 - accuracy: 0.5393 - val_loss: 0.6757 - val_accuracy: 0.4835\n",
            "Epoch 15/35\n",
            "66/66 [==============================] - 48s 721ms/step - loss: 0.6913 - accuracy: 0.5402 - val_loss: 0.6422 - val_accuracy: 0.5074\n",
            "Epoch 16/35\n",
            "66/66 [==============================] - 47s 709ms/step - loss: 0.6928 - accuracy: 0.5402 - val_loss: 0.6459 - val_accuracy: 0.5074\n",
            "Epoch 17/35\n",
            "66/66 [==============================] - 47s 714ms/step - loss: 0.6918 - accuracy: 0.5398 - val_loss: 0.6367 - val_accuracy: 0.5074\n",
            "Epoch 18/35\n",
            "66/66 [==============================] - 47s 718ms/step - loss: 0.6911 - accuracy: 0.5402 - val_loss: 0.6366 - val_accuracy: 0.5074\n",
            "Epoch 19/35\n",
            "66/66 [==============================] - 47s 710ms/step - loss: 0.6908 - accuracy: 0.5407 - val_loss: 0.6221 - val_accuracy: 0.5074\n",
            "Epoch 20/35\n",
            "66/66 [==============================] - 47s 714ms/step - loss: 0.6911 - accuracy: 0.5407 - val_loss: 0.6255 - val_accuracy: 0.5074\n",
            "Epoch 21/35\n",
            "66/66 [==============================] - 47s 711ms/step - loss: 0.6904 - accuracy: 0.5412 - val_loss: 0.6251 - val_accuracy: 0.5074\n",
            "Epoch 22/35\n",
            "66/66 [==============================] - 48s 721ms/step - loss: 0.6907 - accuracy: 0.5739 - val_loss: 8.1524 - val_accuracy: 0.4926\n",
            "Epoch 23/35\n",
            "66/66 [==============================] - 47s 719ms/step - loss: 0.7116 - accuracy: 0.5260 - val_loss: 1.8544 - val_accuracy: 0.4908\n",
            "Epoch 24/35\n",
            "66/66 [==============================] - 47s 715ms/step - loss: 0.6914 - accuracy: 0.5402 - val_loss: 0.8784 - val_accuracy: 0.5257\n",
            "Epoch 25/35\n",
            "66/66 [==============================] - 47s 710ms/step - loss: 0.6906 - accuracy: 0.5398 - val_loss: 0.6216 - val_accuracy: 0.5074\n",
            "Epoch 26/35\n",
            "66/66 [==============================] - 47s 714ms/step - loss: 0.6905 - accuracy: 0.5398 - val_loss: 0.6172 - val_accuracy: 0.5074\n",
            "Epoch 27/35\n",
            "66/66 [==============================] - 47s 714ms/step - loss: 0.6904 - accuracy: 0.5402 - val_loss: 0.6162 - val_accuracy: 0.5074\n",
            "Epoch 28/35\n",
            "66/66 [==============================] - 47s 714ms/step - loss: 0.6962 - accuracy: 0.5393 - val_loss: 0.6134 - val_accuracy: 0.5074\n",
            "Epoch 29/35\n",
            "66/66 [==============================] - 47s 717ms/step - loss: 0.6904 - accuracy: 0.5402 - val_loss: 0.6200 - val_accuracy: 0.5074\n",
            "Epoch 30/35\n",
            "66/66 [==============================] - 47s 712ms/step - loss: 0.6909 - accuracy: 0.5402 - val_loss: 0.6147 - val_accuracy: 0.5074\n",
            "Epoch 31/35\n",
            "66/66 [==============================] - 47s 715ms/step - loss: 0.6910 - accuracy: 0.5402 - val_loss: 0.6195 - val_accuracy: 0.5074\n",
            "Epoch 32/35\n",
            "66/66 [==============================] - 47s 706ms/step - loss: 0.6910 - accuracy: 0.5402 - val_loss: 0.6189 - val_accuracy: 0.5074\n",
            "Epoch 33/35\n",
            "66/66 [==============================] - 47s 712ms/step - loss: 0.6901 - accuracy: 0.5402 - val_loss: 0.6199 - val_accuracy: 0.5074\n",
            "Epoch 34/35\n",
            "66/66 [==============================] - 47s 706ms/step - loss: 0.6912 - accuracy: 0.5398 - val_loss: 0.6217 - val_accuracy: 0.5074\n",
            "Epoch 35/35\n",
            "66/66 [==============================] - 47s 708ms/step - loss: 0.6909 - accuracy: 0.5402 - val_loss: 0.6119 - val_accuracy: 0.5074\n",
            "Training Completed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrqW4KwQL_7r",
        "colab_type": "code",
        "outputId": "d37dd2ed-7634-4956-c4b2-7277b4cf61de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        " # save model and architecture to single file\n",
        "model.save('/content/drive/My Drive/Colab Notebooks/Signature verification scratch model/novel_model.h5')\n",
        "model.summary()\n",
        "\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 224, 224, 64)      23296     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 224, 224, 64)      256       \n",
            "_________________________________________________________________\n",
            "activation_192 (Activation)  (None, 224, 224, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 74, 74, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 74, 74, 128)       401536    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 74, 74, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_193 (Activation)  (None, 74, 74, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 24, 24, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 24, 24, 192)       221376    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 24, 24, 192)       768       \n",
            "_________________________________________________________________\n",
            "activation_194 (Activation)  (None, 24, 24, 192)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 192)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 8, 8, 256)         442624    \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "hidden_layer (Dense)         (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "classification_layer (Dense) (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,230,913\n",
            "Trainable params: 1,229,633\n",
            "Non-trainable params: 1,280\n",
            "_________________________________________________________________\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xgkyiPsnGms",
        "colab_type": "code",
        "outputId": "1b723166-7b0a-47ea-9634-ab7f21b115cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Loading saved model from Drive.\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/Colab Notebooks/Signature verification scratch model/novel_model.h5')\n",
        "print(\"Model is Loaded\")"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model is Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMpmZaCJFPxi",
        "colab_type": "code",
        "outputId": "53cf087b-4a64-4747-b595-50e3ce1f5e75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Intermediate Model construction\n",
        "from keras.models import load_model\n",
        "layer_name= 'classification_layer'\n",
        "intermediate_layer_model = Model(inputs=model.input,\n",
        "                                 outputs=model.get_layer(layer_name).output)\n",
        "print(\"Intermediate model is created\")\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intermediate model is created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ls3jvBMEkj_",
        "colab_type": "code",
        "outputId": "9a190919-5818-46c2-e32d-acb046676d3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Compilation of intermediate model\n",
        "intermediate_layer_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(\"Model is Complied\")"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model is Complied\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hivj_psZpbrU",
        "colab_type": "code",
        "outputId": "0e0f0004-4eb7-424b-dafe-4d9413d0e36c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "# Saving intermediate model\n",
        "intermediate_layer_model.save('/content/drive/My Drive/Colab Notebooks/Signature verification scratch model/novel_intermediate_model.h5')\n",
        "intermediate_layer_model.summary()\n",
        "\n",
        "print(\"Saved Intermediate model to disk\")"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6_input (InputLayer)  (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 224, 224, 64)      23296     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 224, 224, 64)      256       \n",
            "_________________________________________________________________\n",
            "activation_192 (Activation)  (None, 224, 224, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 74, 74, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 74, 74, 128)       401536    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 74, 74, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_193 (Activation)  (None, 74, 74, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 24, 24, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 24, 24, 192)       221376    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 24, 24, 192)       768       \n",
            "_________________________________________________________________\n",
            "activation_194 (Activation)  (None, 24, 24, 192)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 192)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 8, 8, 256)         442624    \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "hidden_layer (Dense)         (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "classification_layer (Dense) (None, 64)                8256      \n",
            "=================================================================\n",
            "Total params: 1,230,848\n",
            "Trainable params: 1,229,568\n",
            "Non-trainable params: 1,280\n",
            "_________________________________________________________________\n",
            "Saved Intermediate model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT373FILp0_e",
        "colab_type": "code",
        "outputId": "9567206f-2274-457f-fe0f-e0afd3627fba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Loading Intermediate Model\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/My Drive/Colab Notebooks/Signature verification scratch model/novel_intermediate_model.h5')\n",
        "print(\"Intermediate model is loaded\")"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intermediate model is loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tawP0q3yqGBO",
        "colab_type": "code",
        "outputId": "70fa7aa8-4bec-44ff-dbd2-c879d199feef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Training Label feature identification(y_train)\n",
        " import numpy as np\n",
        " batch_size=32\n",
        " sample_count=2112\n",
        " features = np.zeros(shape=(2112, 64))  # Must be equal to the output of the convolutional base\n",
        " labels = np.zeros(shape=(2112))\n",
        " i = 0\n",
        " for inputs_batch, labels_batch in train_generator:\n",
        "   features_batch = model.predict(inputs_batch)\n",
        "   features[i * batch_size: (i + 1) * batch_size] = features_batch\n",
        "   labels[i * batch_size: (i + 1) * batch_size] = labels_batch\n",
        "   i += 1\n",
        "   if i*batch_size  >= sample_count:\n",
        "     break\n",
        " print(labels.shape)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2112,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl7T9UrMqKGo",
        "colab_type": "code",
        "outputId": "01be1f85-c665-4c69-e3eb-efcb7130bace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "#identification of training Labels\n",
        "features_train=features\n",
        "print(features_train.shape)\n",
        "labels_train=np.expand_dims(labels, axis=1)\n",
        "print(labels_train.shape)\n",
        "print(labels_train)#identification of training Labels\n",
        "features_train=features\n",
        "print(features_train.shape)\n",
        "print(features_train)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2112, 64)\n",
            "(2112, 1)\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " ...\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n",
            "(2112, 64)\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdMzIPE1qNhX",
        "colab_type": "code",
        "outputId": "73ee2dbc-d712-417d-a248-b80e6760ee7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "#identification of training Labels\n",
        "features_train=features\n",
        "print(features_train.shape)\n",
        "labels_train=np.expand_dims(labels, axis=1)\n",
        "print(labels_train.shape)\n",
        "print(labels_train)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2112, 64)\n",
            "(2112, 1)\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " ...\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SBF1J3vqQ4W",
        "colab_type": "code",
        "outputId": "34b39c25-1f01-432d-8065-5f5949e3645a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "# identification of test labels\n",
        " import numpy as np\n",
        " batch_size=32\n",
        " sample_count=544\n",
        " features_test = np.zeros(shape=(544, 64))  # Must be equal to the output of the convolutional base\n",
        " labels_test = np.zeros(shape=(544))\n",
        " i = 0\n",
        " for inputs_batch, labels_batch in validation_generator:\n",
        "   features_batch = model.predict(inputs_batch)\n",
        "   features_test[i * batch_size: (i + 1) * batch_size] = features_batch\n",
        "   labels_test[i * batch_size: (i + 1) * batch_size] = labels_batch\n",
        "   i += 1\n",
        "   if i*batch_size  >= sample_count:\n",
        "     break\n",
        " print(labels_test.shape)\n",
        " print(features_test.shape)\n",
        " print(labels_test)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(544,)\n",
            "(544, 64)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dih8QbQqUel",
        "colab_type": "code",
        "outputId": "6fcf897c-6477-4507-e7bb-43255fa1ef31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# #identification of testing Labels\n",
        "print(features_test.shape)\n",
        "print(features_test)\n",
        "labels_test=np.expand_dims(labels_test, axis=1)\n",
        "print(labels_test.shape)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(544, 64)\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "(544, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYX4UkEYqZJb",
        "colab_type": "code",
        "outputId": "1ad183f9-0dde-4031-8a17-6d58acad820c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# SVM\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(features_train)\n",
        "X_test = sc.transform(features_test)\n",
        "\n",
        "# Fitting SVM to the Training set\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'linear', random_state = 0)\n",
        "classifier.fit(X_train,labels_train.ravel())\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(labels_test, y_pred)\n",
        "print(cm)\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(labels_test, y_pred))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  2 266]\n",
            " [  2 274]]\n",
            "0.5073529411764706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piTDuGdvNd9z",
        "colab_type": "code",
        "outputId": "61700948-c645-4c45-a9a8-11b08ca6d2d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\n",
        "# Kernel SVM\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(features_train)\n",
        "X_test = sc.transform(features_test)\n",
        "\n",
        "# Fitting KernelSVM to the Training set\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
        "classifier.fit(X_train, labels_train.ravel())\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(labels_test, y_pred)\n",
        "print(cm)\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(labels_test, y_pred))\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  2 266]\n",
            " [  1 275]]\n",
            "0.5091911764705882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeyaANSC1zeA",
        "colab_type": "code",
        "outputId": "92900dcf-e981-41b0-d900-07d26a342b2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Random Forest\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(features_train)\n",
        "X_test = sc.transform(features_test)\n",
        "\n",
        "# Fitting KernelSVM to the Training set\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, labels_train.ravel())\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(labels_test, y_pred)\n",
        "print(cm)\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(labels_test, y_pred))\n",
        "\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  4 264]\n",
            " [  2 274]]\n",
            "0.5110294117647058\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qBoJeVA7cA0",
        "colab_type": "code",
        "outputId": "a2c2a1fd-bade-427b-a5e0-cdf7d5b00411",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Decision Tree\n",
        "# Feature Scaling\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(features_train)\n",
        "X_test = sc.transform(features_test)\n",
        "\n",
        "# Fitting KernelSVM to the Training set\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, labels_train.ravel())\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(labels_test, y_pred)\n",
        "print(cm)\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(labels_test, y_pred))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  4 264]\n",
            " [  3 273]]\n",
            "0.5091911764705882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUxX29IQ8Pex",
        "colab_type": "code",
        "outputId": "6874e050-1ce6-4d94-d2f4-d27345df231b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\n",
        "# Naive Bayes\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(features_train)\n",
        "X_test = sc.transform(features_test)\n",
        "\n",
        "# Fitting KernelSVM to the Training set\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, labels_train.ravel())\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(labels_test, y_pred)\n",
        "print(cm)\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(labels_test, y_pred))\n"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[264   4]\n",
            " [274   2]]\n",
            "0.4889705882352941\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrmXyTdm8nUR",
        "colab_type": "code",
        "outputId": "fa389b91-ef7f-4fed-9468-43e6dc880785",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(features_train)\n",
        "X_test = sc.transform(features_test)\n",
        "\n",
        "# Fitting KernelSVM to the Training set\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier =  KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
        "classifier.fit(X_train, labels_train.ravel())\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(labels_test, y_pred)\n",
        "print(cm)\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(labels_test, y_pred))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[264   4]\n",
            " [274   2]]\n",
            "0.4889705882352941\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4qIzREF8-uz",
        "colab_type": "code",
        "outputId": "11b725a2-02dd-4e79-d45c-843196d7ca6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(features_train)\n",
        "X_test = sc.transform(features_test)\n",
        "\n",
        "# Fitting KernelSVM to the Training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train, labels_train.ravel())\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(labels_test, y_pred)\n",
        "print(cm)\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(labels_test, y_pred))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  1 267]\n",
            " [  2 274]]\n",
            "0.5055147058823529\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "75225bc6-d272-4834-de63-d30eb045e318",
        "id": "sCESN-7A9ejM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/My Drive/Colab Notebooks/Signature verification scratch model/novel_model.h5')\n",
        "# Evaluate the model on the test data using `evaluate`\n",
        "print('\\n# Evaluate on test data')\n",
        "results = model.evaluate(validation_generator)\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# Evaluate on test data\n",
            "17/17 [==============================] - 4s 211ms/step\n",
            "test loss, test acc: [0.6119047403335571, 0.5073529481887817]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}