{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Signature Verification Vgg Model GDPS dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPJD+wlKMvG/d5cWNhm9SfF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepakmoud/Signature-Verification/blob/master/Signature_Verification_Vgg_Model_GDPS_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Sf8lLdMYsCh",
        "colab_type": "code",
        "outputId": "68219519-64f4-4463-8536-da19f7b83f35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Importing the Keras libraries and packages\n",
        "from keras.layers import Input, Flatten, Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Flatten, Dense\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "img_width, img_height = 224, 224\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbzwJF19Y0ct",
        "colab_type": "code",
        "outputId": "ae9efd9d-2d9c-4154-a4e9-504c8110b985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Updating Keras\n",
        "pip install -U keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.3)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90n6dcKIY3by",
        "colab_type": "code",
        "outputId": "f66e52cb-6464-4b22-92ee-6aded34226be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Load the pretrained Network\n",
        "vgg16_model = VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(img_height,img_width,3), pooling=None, classes=1000)\n",
        "print(\"pretrained Network is loaded\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n",
            "pretrained Network is loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yed6-8x8Y6bM",
        "colab_type": "code",
        "outputId": "5606eeb8-2151-4fb1-b326-2897958a9a67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Freeze the layers\n",
        "for layer in vgg16_model.layers:\n",
        "    layer.trainable = False\n",
        "print(\"Pretrained layers are freezed\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pretrained layers are freezed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-VeGiMVY--2",
        "colab_type": "code",
        "outputId": "d4ad7358-7cd7-4025-f3a2-89ac5e219d7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Model Buliding\n",
        "model = Sequential()\n",
        "model.add(vgg16_model)\n",
        "#add fully connected layer:\n",
        "input_layer=model.add(Flatten())\n",
        "hidden_layer=model.add(Dense(128, activation='relu', name='hidden_layer'))\n",
        "classification_layer=model.add(Dense(64, activation='relu', name='classification_layer'))\n",
        "output_layer=model.add(Dense(1, activation='sigmoid', name='output_layer')) \n",
        "print(\"All layers top of pretrained layers are developed\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All layers top of pretrained layers are developed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJJplrQeZDKx",
        "colab_type": "code",
        "outputId": "33ab4c91-64a0-402a-dfda-05caa2f5e95c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Input parameter\n",
        "train_data_dir ='/content/drive/My Drive/Colab Notebooks/Dataset GDPS/train_dir'\n",
        "val_data_dir ='/content/drive/My Drive/Colab Notebooks/Dataset GDPS/val_dir'\n",
        "model_weights_file = '/content/drive/My Drive/Colab Notebooks/Signature Verification vgg16 model GDPS/model_vgg16_weights.hdf5'\n",
        "nb_epochs = 50\n",
        "print(\"Input parameters are assigned\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input parameters are assigned\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13L22j2RZHrq",
        "colab_type": "code",
        "outputId": "bbb384b4-e5cd-49bf-9b36-8d9012e5bcc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(\"Model is Complied\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model is Complied\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48tUhIKiZMvm",
        "colab_type": "code",
        "outputId": "91c83282-9104-403f-c53f-2e15c8731a15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNuqzITRZPn8",
        "colab_type": "code",
        "outputId": "26f581c9-673c-438b-af36-ed3cd1964739",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# image data generation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_width, img_height), \n",
        "                                                    batch_size=32,shuffle=False, class_mode='binary')\n",
        "validation_generator = test_datagen.flow_from_directory(val_data_dir, target_size=(img_width, img_height), \n",
        "                                                    batch_size=32,shuffle=False,class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 18016 images belonging to 2 classes.\n",
            "Found 3584 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A93j5hMZVg_",
        "colab_type": "code",
        "outputId": "ef614b7c-5c8e-453b-a295-3793b78540a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "callbacks = [ModelCheckpoint(model_weights_file, monitor='val_acc', save_best_only=True)]\n",
        "\n",
        "history = model.fit_generator( train_generator, callbacks = callbacks, nb_epoch=nb_epochs, validation_data=validation_generator)\n",
        "\n",
        "print('Training Completed!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "563/563 [==============================] - 10276s 18s/step - loss: 0.8248 - accuracy: 0.5340 - val_loss: 0.6851 - val_accuracy: 0.4481\n",
            "Epoch 2/50\n",
            "563/563 [==============================] - 282s 500ms/step - loss: 0.6878 - accuracy: 0.5367 - val_loss: 0.7090 - val_accuracy: 0.5578\n",
            "Epoch 3/50\n",
            "563/563 [==============================] - 280s 497ms/step - loss: 0.6710 - accuracy: 0.5556 - val_loss: 0.7043 - val_accuracy: 0.5578\n",
            "Epoch 4/50\n",
            "563/563 [==============================] - 275s 488ms/step - loss: 0.6577 - accuracy: 0.5712 - val_loss: 0.7039 - val_accuracy: 0.6593\n",
            "Epoch 5/50\n",
            "563/563 [==============================] - 282s 502ms/step - loss: 0.6595 - accuracy: 0.5866 - val_loss: 0.6829 - val_accuracy: 0.6289\n",
            "Epoch 6/50\n",
            "563/563 [==============================] - 286s 508ms/step - loss: 0.6483 - accuracy: 0.6104 - val_loss: 0.7311 - val_accuracy: 0.6593\n",
            "Epoch 7/50\n",
            "563/563 [==============================] - 288s 512ms/step - loss: 0.6548 - accuracy: 0.5980 - val_loss: 0.7356 - val_accuracy: 0.6574\n",
            "Epoch 8/50\n",
            "563/563 [==============================] - 284s 505ms/step - loss: 0.6502 - accuracy: 0.6088 - val_loss: 0.6920 - val_accuracy: 0.6546\n",
            "Epoch 9/50\n",
            "563/563 [==============================] - 273s 485ms/step - loss: 0.6522 - accuracy: 0.6086 - val_loss: 0.6925 - val_accuracy: 0.6632\n",
            "Epoch 10/50\n",
            "563/563 [==============================] - 269s 477ms/step - loss: 0.6428 - accuracy: 0.6252 - val_loss: 0.6267 - val_accuracy: 0.6560\n",
            "Epoch 11/50\n",
            "563/563 [==============================] - 265s 471ms/step - loss: 0.6377 - accuracy: 0.6304 - val_loss: 0.7070 - val_accuracy: 0.6627\n",
            "Epoch 12/50\n",
            "563/563 [==============================] - 263s 467ms/step - loss: 0.6342 - accuracy: 0.6317 - val_loss: 0.6530 - val_accuracy: 0.6733\n",
            "Epoch 13/50\n",
            "563/563 [==============================] - 263s 467ms/step - loss: 0.6403 - accuracy: 0.6309 - val_loss: 0.5794 - val_accuracy: 0.5776\n",
            "Epoch 14/50\n",
            "563/563 [==============================] - 263s 468ms/step - loss: 0.6380 - accuracy: 0.6269 - val_loss: 0.7518 - val_accuracy: 0.6593\n",
            "Epoch 15/50\n",
            "563/563 [==============================] - 265s 470ms/step - loss: 0.6270 - accuracy: 0.6395 - val_loss: 0.7131 - val_accuracy: 0.6666\n",
            "Epoch 16/50\n",
            "563/563 [==============================] - 264s 469ms/step - loss: 0.6382 - accuracy: 0.6327 - val_loss: 0.5705 - val_accuracy: 0.6482\n",
            "Epoch 17/50\n",
            "563/563 [==============================] - 264s 469ms/step - loss: 0.6330 - accuracy: 0.6279 - val_loss: 0.6650 - val_accuracy: 0.6789\n",
            "Epoch 18/50\n",
            "563/563 [==============================] - 264s 469ms/step - loss: 0.6276 - accuracy: 0.6447 - val_loss: 0.6078 - val_accuracy: 0.6872\n",
            "Epoch 19/50\n",
            "563/563 [==============================] - 263s 467ms/step - loss: 0.6284 - accuracy: 0.6426 - val_loss: 0.5677 - val_accuracy: 0.6802\n",
            "Epoch 20/50\n",
            "563/563 [==============================] - 263s 467ms/step - loss: 0.6169 - accuracy: 0.6541 - val_loss: 0.7686 - val_accuracy: 0.6420\n",
            "Epoch 21/50\n",
            "563/563 [==============================] - 262s 465ms/step - loss: 0.6272 - accuracy: 0.6498 - val_loss: 0.6300 - val_accuracy: 0.6755\n",
            "Epoch 22/50\n",
            "563/563 [==============================] - 262s 465ms/step - loss: 0.6135 - accuracy: 0.6533 - val_loss: 0.6479 - val_accuracy: 0.6819\n",
            "Epoch 23/50\n",
            "563/563 [==============================] - 268s 476ms/step - loss: 0.6126 - accuracy: 0.6557 - val_loss: 0.5166 - val_accuracy: 0.6161\n",
            "Epoch 24/50\n",
            "563/563 [==============================] - 278s 494ms/step - loss: 0.6275 - accuracy: 0.6379 - val_loss: 0.5457 - val_accuracy: 0.6691\n",
            "Epoch 25/50\n",
            "563/563 [==============================] - 281s 500ms/step - loss: 0.6131 - accuracy: 0.6602 - val_loss: 0.5474 - val_accuracy: 0.6892\n",
            "Epoch 26/50\n",
            "563/563 [==============================] - 284s 505ms/step - loss: 0.6067 - accuracy: 0.6660 - val_loss: 0.5575 - val_accuracy: 0.6973\n",
            "Epoch 27/50\n",
            "563/563 [==============================] - 272s 484ms/step - loss: 0.6146 - accuracy: 0.6523 - val_loss: 0.6486 - val_accuracy: 0.6797\n",
            "Epoch 28/50\n",
            "563/563 [==============================] - 266s 473ms/step - loss: 0.6141 - accuracy: 0.6539 - val_loss: 0.5784 - val_accuracy: 0.7026\n",
            "Epoch 29/50\n",
            "563/563 [==============================] - 266s 472ms/step - loss: 0.5970 - accuracy: 0.6722 - val_loss: 0.6240 - val_accuracy: 0.6920\n",
            "Epoch 30/50\n",
            "563/563 [==============================] - 263s 467ms/step - loss: 0.6102 - accuracy: 0.6607 - val_loss: 0.8207 - val_accuracy: 0.6381\n",
            "Epoch 31/50\n",
            "563/563 [==============================] - 262s 466ms/step - loss: 0.6094 - accuracy: 0.6614 - val_loss: 0.4942 - val_accuracy: 0.6331\n",
            "Epoch 32/50\n",
            "563/563 [==============================] - 261s 464ms/step - loss: 0.6079 - accuracy: 0.6541 - val_loss: 0.5105 - val_accuracy: 0.6624\n",
            "Epoch 33/50\n",
            "563/563 [==============================] - 261s 464ms/step - loss: 0.6028 - accuracy: 0.6639 - val_loss: 0.5025 - val_accuracy: 0.6719\n",
            "Epoch 34/50\n",
            "563/563 [==============================] - 262s 465ms/step - loss: 0.6068 - accuracy: 0.6554 - val_loss: 0.6134 - val_accuracy: 0.7023\n",
            "Epoch 35/50\n",
            "563/563 [==============================] - 262s 465ms/step - loss: 0.6012 - accuracy: 0.6667 - val_loss: 0.5640 - val_accuracy: 0.7084\n",
            "Epoch 36/50\n",
            "563/563 [==============================] - 261s 464ms/step - loss: 0.5991 - accuracy: 0.6705 - val_loss: 0.6740 - val_accuracy: 0.6722\n",
            "Epoch 37/50\n",
            "563/563 [==============================] - 261s 464ms/step - loss: 0.5977 - accuracy: 0.6613 - val_loss: 0.5244 - val_accuracy: 0.7162\n",
            "Epoch 38/50\n",
            "563/563 [==============================] - 262s 465ms/step - loss: 0.6035 - accuracy: 0.6621 - val_loss: 0.7186 - val_accuracy: 0.6722\n",
            "Epoch 39/50\n",
            "563/563 [==============================] - 261s 464ms/step - loss: 0.6000 - accuracy: 0.6704 - val_loss: 0.6326 - val_accuracy: 0.6967\n",
            "Epoch 40/50\n",
            "563/563 [==============================] - 262s 465ms/step - loss: 0.6031 - accuracy: 0.6670 - val_loss: 0.4974 - val_accuracy: 0.7129\n",
            "Epoch 41/50\n",
            "563/563 [==============================] - 261s 464ms/step - loss: 0.5940 - accuracy: 0.6717 - val_loss: 0.6270 - val_accuracy: 0.6914\n",
            "Epoch 42/50\n",
            "563/563 [==============================] - 262s 465ms/step - loss: 0.5939 - accuracy: 0.6730 - val_loss: 1.0601 - val_accuracy: 0.5999\n",
            "Epoch 43/50\n",
            "563/563 [==============================] - 263s 466ms/step - loss: 0.5897 - accuracy: 0.6778 - val_loss: 0.6064 - val_accuracy: 0.6931\n",
            "Epoch 44/50\n",
            "563/563 [==============================] - 262s 465ms/step - loss: 0.5916 - accuracy: 0.6707 - val_loss: 0.5641 - val_accuracy: 0.7059\n",
            "Epoch 45/50\n",
            "563/563 [==============================] - 261s 464ms/step - loss: 0.5942 - accuracy: 0.6712 - val_loss: 0.5581 - val_accuracy: 0.7229\n",
            "Epoch 46/50\n",
            "563/563 [==============================] - 262s 465ms/step - loss: 0.5895 - accuracy: 0.6827 - val_loss: 0.5486 - val_accuracy: 0.7227\n",
            "Epoch 47/50\n",
            "563/563 [==============================] - 261s 464ms/step - loss: 0.5851 - accuracy: 0.6854 - val_loss: 0.5448 - val_accuracy: 0.7157\n",
            "Epoch 48/50\n",
            "563/563 [==============================] - 261s 464ms/step - loss: 0.5819 - accuracy: 0.6875 - val_loss: 0.8605 - val_accuracy: 0.6286\n",
            "Epoch 49/50\n",
            "563/563 [==============================] - 261s 463ms/step - loss: 0.5810 - accuracy: 0.6857 - val_loss: 0.6183 - val_accuracy: 0.6970\n",
            "Epoch 50/50\n",
            "563/563 [==============================] - 261s 464ms/step - loss: 0.5891 - accuracy: 0.6785 - val_loss: 0.6363 - val_accuracy: 0.7020\n",
            "Training Completed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66v0MvyvZZDW",
        "colab_type": "code",
        "outputId": "98984b6d-74fe-43a7-a011-6145b6ef1c31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        " # save model and architecture to single file\n",
        "model.save('/content/drive/My Drive/Colab Notebooks/Signature Verification vgg16 model GDPS/model_vgg16_GDPS.h5')\n",
        "model.summary()\n",
        "\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "hidden_layer (Dense)         (None, 128)               3211392   \n",
            "_________________________________________________________________\n",
            "classification_layer (Dense) (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 17,934,401\n",
            "Trainable params: 3,219,713\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFq0H2-BZcjS",
        "colab_type": "code",
        "outputId": "d34179f6-9cc1-4d4f-8779-a91bf775d909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# save weights to single file\n",
        "model.save_weights('/content/drive/My Drive/Colab Notebooks/Signature Verification vgg16 model GDPS/model_vgg16_weights_GDPS.h5')\n",
        "print(\"Weights saved in Drive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights saved in Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZAi-ofxZgR8",
        "colab_type": "code",
        "outputId": "af653ae1-04ee-4824-dd4d-79f950f45a2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Loading saved model from Drive.\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/Colab Notebooks/Signature Verification vgg16 model GDPS/model_vgg16_GDPS.h5')\n",
        "print(\"Model is Loaded\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model is Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycbMLOcjZnmk",
        "colab_type": "code",
        "outputId": "b8692643-72dd-420a-a35a-60675678fdab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Extracting Features from classification Layer\n",
        "from keras.models import Model\n",
        "layer_name= 'classification_layer'\n",
        "intermediate_layer_model = Model(inputs=model.input,\n",
        "                                 outputs=model.get_layer(layer_name).output)\n",
        "print(\"Imtermediate model is constructed\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imtermediate model is constructed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb3rfV35Z0nr",
        "colab_type": "code",
        "outputId": "e945cc01-064d-4ed8-b25e-bc857247f94a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Compilation of intermediate model\n",
        "intermediate_layer_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(\"Model is Complied\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model is Complied\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjU09Es5Z4Fp",
        "colab_type": "code",
        "outputId": "3ac70a4d-938b-42d4-dcbf-bc51aac2dc5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "# Saving intermediate model\n",
        "intermediate_layer_model.save('/content/drive/My Drive/Colab Notebooks/Signature Verification vgg16 model GDPS/intermediate_model_vgg16_GDPS.h5')\n",
        "intermediate_layer_model.summary()\n",
        "\n",
        "print(\"Saved Intermediate model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16_input (InputLayer)     (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "hidden_layer (Dense)         (None, 128)               3211392   \n",
            "_________________________________________________________________\n",
            "classification_layer (Dense) (None, 64)                8256      \n",
            "=================================================================\n",
            "Total params: 17,934,336\n",
            "Trainable params: 3,219,648\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "Saved Intermediate model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TqY_4BnZ8PX",
        "colab_type": "code",
        "outputId": "07a33589-cca8-4b70-e21f-3fc1eda36633",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Loading Intermediate Model\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/My Drive/Colab Notebooks/Signature Verification vgg16 model GDPS/intermediate_model_vgg16_GDPS.h5')\n",
        "print(\"Intermediate model is loaded\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intermediate model is loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L31_WFZaB1L",
        "colab_type": "code",
        "outputId": "add94d2d-b95e-4f7d-db42-bb9550b4cafa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Training Label feature identification(y_train)\n",
        " import numpy as np\n",
        " batch_size=32\n",
        " sample_count=18016\n",
        " features = np.zeros(shape=(18016, 64))  # Must be equal to the output of the convolutional base\n",
        " labels = np.zeros(shape=(18016))\n",
        " i = 0\n",
        " for inputs_batch, labels_batch in train_generator:\n",
        "   features_batch = model.predict(inputs_batch)\n",
        "   features[i * batch_size: (i + 1) * batch_size] = features_batch\n",
        "   labels[i * batch_size: (i + 1) * batch_size] = labels_batch\n",
        "   i += 1\n",
        "   if i*batch_size  >= sample_count:\n",
        "     break\n",
        " print(labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18016,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTKFifVGaH-D",
        "colab_type": "code",
        "outputId": "e1dc350a-53d6-4e57-a08f-d70706a24ec8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "#identification of training Labels\n",
        "features_train=features\n",
        "print(features_train.shape)\n",
        "labels_train=np.expand_dims(labels, axis=1)\n",
        "print(labels_train.shape)\n",
        "print(labels_train)\n",
        "print(features_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18016, 64)\n",
            "(18016, 1)\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " ...\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "[[0.         0.25722879 0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.25722879 0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.25722879 0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuqyZ1VjaLMJ",
        "colab_type": "code",
        "outputId": "f5e00603-cdc1-47d9-b305-1e34e60f532c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# identification of test labels\n",
        " import numpy as np\n",
        " batch_size=32\n",
        " sample_count=3584\n",
        " features_test = np.zeros(shape=(3584, 64))  # Must be equal to the output of the convolutional base\n",
        " labels_test = np.zeros(shape=(3584))\n",
        " i = 0\n",
        " for inputs_batch, labels_batch in validation_generator:\n",
        "   features_batch = model.predict(inputs_batch)\n",
        "   features_test[i * batch_size: (i + 1) * batch_size] = features_batch\n",
        "   labels_test[i * batch_size: (i + 1) * batch_size] = labels_batch\n",
        "   i += 1\n",
        "   if i*batch_size  >= sample_count:\n",
        "     break\n",
        " print(labels_test.shape)\n",
        " print(features_test.shape)\n",
        " print(labels_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3584,)\n",
            "(3584, 64)\n",
            "[0. 0. 0. ... 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sxB-SqcaPTV",
        "colab_type": "code",
        "outputId": "0e7e7f5e-25d8-4acf-e720-752fd3d072df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# #identification of testing Labels\n",
        "print(features_test.shape)\n",
        "labels_test=np.expand_dims(labels_test, axis=1)\n",
        "print(labels_test.shape)\n",
        "print(features_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3584, 64)\n",
            "(3584, 1)\n",
            "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.0277618  0.         0.         ... 0.00553526 0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.25722879 0.         ... 0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXPaTjNEaTDO",
        "colab_type": "code",
        "outputId": "38295c87-9bc9-4fc0-a4b5-4bbd80e022ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# SVM\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(features_train)\n",
        "X_test = sc.transform(features_test)\n",
        "\n",
        "# Fitting SVM to the Training set\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'linear', random_state = 0)\n",
        "classifier.fit(X_train,labels_train.ravel())\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(labels_test, y_pred)\n",
        "print('Confusion matrix: ')\n",
        "print(cm)\n",
        "# calculate Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('Accuracy: %.3f' % (accuracy_score(labels_test, y_pred)*100))\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "# calculate precision\n",
        "# Precision = TruePositives / (TruePositives + FalsePositives)\n",
        "precision = precision_score(labels_test, y_pred, average='binary')\n",
        "print('Precision: %.3f' % (precision*100))\n",
        "# calculate recall\n",
        "# Recall = TruePositives / (TruePositives + FalseNegatives)\n",
        "recall = recall_score(labels_test, y_pred, average='binary')\n",
        "print('Recall: %.3f' % (recall*100))\n",
        "# F-Measure = (2 * Precision * Recall) / (Precision + Recall)\n",
        "# calculate score\n",
        "score = f1_score(labels_test, y_pred, average='binary')\n",
        "print('F-Measure: %.3f' % (score*100))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix: \n",
            "[[1547  452]\n",
            " [ 517 1068]]\n",
            "Accuracy: 72.963\n",
            "Precision: 70.263\n",
            "Recall: 67.382\n",
            "F-Measure: 68.792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK7WfMXhaWy5",
        "colab_type": "code",
        "outputId": "7a1e7f87-2353-4c21-c73c-6453a7ff3849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Kernel SVM\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(features_train)\n",
        "X_test = sc.transform(features_test)\n",
        "\n",
        "# Fitting KernelSVM to the Training set\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
        "classifier.fit(X_train, labels_train.ravel())\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(labels_test, y_pred)\n",
        "print('Confusion matrix: ')\n",
        "print(cm)\n",
        "# calculate Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('Accuracy: %.3f' % (accuracy_score(labels_test, y_pred)*100))\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "# calculate precision\n",
        "# Precision = TruePositives / (TruePositives + FalsePositives)\n",
        "precision = precision_score(labels_test, y_pred, average='binary')\n",
        "print('Precision: %.3f' % (precision*100))\n",
        "# calculate recall\n",
        "# Recall = TruePositives / (TruePositives + FalseNegatives)\n",
        "recall = recall_score(labels_test, y_pred, average='binary')\n",
        "print('Recall: %.3f' % (recall*100))\n",
        "# F-Measure = (2 * Precision * Recall) / (Precision + Recall)\n",
        "# calculate score\n",
        "score = f1_score(labels_test, y_pred, average='binary')\n",
        "print('F-Measure: %.3f' % (score*100))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix: \n",
            "[[1534  465]\n",
            " [ 500 1085]]\n",
            "Accuracy: 73.075\n",
            "Precision: 70.000\n",
            "Recall: 68.454\n",
            "F-Measure: 69.219\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRNFNMveaah7",
        "colab_type": "code",
        "outputId": "f088fe27-7e58-4bab-fe4e-07fc044ae0c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Random Forest\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(features_train)\n",
        "X_test = sc.transform(features_test)\n",
        "\n",
        "# Fitting KernelSVM to the Training set\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, labels_train.ravel())\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(labels_test, y_pred)\n",
        "print('Confusion matrix: ')\n",
        "print(cm)\n",
        "# calculate Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('Accuracy: %.3f' % (accuracy_score(labels_test, y_pred)*100))\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "# calculate precision\n",
        "# Precision = TruePositives / (TruePositives + FalsePositives)\n",
        "precision = precision_score(labels_test, y_pred, average='binary')\n",
        "print('Precision: %.3f' % (precision*100))\n",
        "# calculate recall\n",
        "# Recall = TruePositives / (TruePositives + FalseNegatives)\n",
        "recall = recall_score(labels_test, y_pred, average='binary')\n",
        "print('Recall: %.3f' % (recall*100))\n",
        "# F-Measure = (2 * Precision * Recall) / (Precision + Recall)\n",
        "# calculate score\n",
        "score = f1_score(labels_test, y_pred, average='binary')\n",
        "print('F-Measure: %.3f' % (score*100))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix: \n",
            "[[1399  600]\n",
            " [ 573 1012]]\n",
            "Accuracy: 67.271\n",
            "Precision: 62.779\n",
            "Recall: 63.849\n",
            "F-Measure: 63.309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv2jInXOakFa",
        "colab_type": "code",
        "outputId": "db39c23e-c34d-4282-a9fb-5bcf37c68f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Random Forest\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(features_train)\n",
        "X_test = sc.transform(features_test)\n",
        "\n",
        "# Fitting KernelSVM to the Training set\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, labels_train.ravel())\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(labels_test, y_pred)\n",
        "print('Confusion matrix: ')\n",
        "print(cm)\n",
        "# calculate Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('Accuracy: %.3f' % (accuracy_score(labels_test, y_pred)*100))\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "# calculate precision\n",
        "# Precision = TruePositives / (TruePositives + FalsePositives)\n",
        "precision = precision_score(labels_test, y_pred, average='binary')\n",
        "print('Precision: %.3f' % (precision*100))\n",
        "# calculate recall\n",
        "# Recall = TruePositives / (TruePositives + FalseNegatives)\n",
        "recall = recall_score(labels_test, y_pred, average='binary')\n",
        "print('Recall: %.3f' % (recall*100))\n",
        "# F-Measure = (2 * Precision * Recall) / (Precision + Recall)\n",
        "# calculate score\n",
        "score = f1_score(labels_test, y_pred, average='binary')\n",
        "print('F-Measure: %.3f' % (score*100))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix: \n",
            "[[1399  600]\n",
            " [ 573 1012]]\n",
            "Accuracy: 67.271\n",
            "Precision: 62.779\n",
            "Recall: 63.849\n",
            "F-Measure: 63.309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu_p4Ux7apAA",
        "colab_type": "code",
        "outputId": "e7604cbe-2444-4215-b4da-a387a73f32cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Naive Bayes\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(features_train)\n",
        "X_test = sc.transform(features_test)\n",
        "\n",
        "# Fitting KernelSVM to the Training set\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, labels_train.ravel())\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(labels_test, y_pred)\n",
        "print('Confusion matrix: ')\n",
        "print(cm)\n",
        "# calculate Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('Accuracy: %.3f' % (accuracy_score(labels_test, y_pred)*100))\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "# calculate precision\n",
        "# Precision = TruePositives / (TruePositives + FalsePositives)\n",
        "precision = precision_score(labels_test, y_pred, average='binary')\n",
        "print('Precision: %.3f' % (precision*100))\n",
        "# calculate recall\n",
        "# Recall = TruePositives / (TruePositives + FalseNegatives)\n",
        "recall = recall_score(labels_test, y_pred, average='binary')\n",
        "print('Recall: %.3f' % (recall*100))\n",
        "# F-Measure = (2 * Precision * Recall) / (Precision + Recall)\n",
        "# calculate score\n",
        "score = f1_score(labels_test, y_pred, average='binary')\n",
        "print('F-Measure: %.3f' % (score*100))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix: \n",
            "[[ 571 1428]\n",
            " [  13 1572]]\n",
            "Accuracy: 59.794\n",
            "Precision: 52.400\n",
            "Recall: 99.180\n",
            "F-Measure: 68.571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnfeZ4eVavhm",
        "colab_type": "code",
        "outputId": "2829fe02-479b-4aee-a9e8-b480a44fd5a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(features_train)\n",
        "X_test = sc.transform(features_test)\n",
        "\n",
        "# Fitting KernelSVM to the Training set\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier =  KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
        "classifier.fit(X_train, labels_train.ravel())\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(labels_test, y_pred)\n",
        "print('Confusion matrix: ')\n",
        "print(cm)\n",
        "# calculate Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('Accuracy: %.3f' % (accuracy_score(labels_test, y_pred)*100))\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "# calculate precision\n",
        "# Precision = TruePositives / (TruePositives + FalsePositives)\n",
        "precision = precision_score(labels_test, y_pred, average='binary')\n",
        "print('Precision: %.3f' % (precision*100))\n",
        "# calculate recall\n",
        "# Recall = TruePositives / (TruePositives + FalseNegatives)\n",
        "recall = recall_score(labels_test, y_pred, average='binary')\n",
        "print('Recall: %.3f' % (recall*100))\n",
        "# F-Measure = (2 * Precision * Recall) / (Precision + Recall)\n",
        "# calculate score\n",
        "score = f1_score(labels_test, y_pred, average='binary')\n",
        "print('F-Measure: %.3f' % (score*100))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix: \n",
            "[[1641  358]\n",
            " [1079  506]]\n",
            "Accuracy: 59.905\n",
            "Precision: 58.565\n",
            "Recall: 31.924\n",
            "F-Measure: 41.323\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsHQZapTazre",
        "colab_type": "code",
        "outputId": "20415cfc-f5a5-46f0-a640-df64f0626191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(features_train)\n",
        "X_test = sc.transform(features_test)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train, labels_train.ravel())\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(labels_test, y_pred)\n",
        "print('Confusion matrix: ')\n",
        "print(cm)\n",
        "# calculate Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('Accuracy: %.3f' % (accuracy_score(labels_test, y_pred)*100))\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "# calculate precision\n",
        "# Precision = TruePositives / (TruePositives + FalsePositives)\n",
        "precision = precision_score(labels_test, y_pred, average='binary')\n",
        "print('Precision: %.3f' % (precision*100))\n",
        "# calculate recall\n",
        "# Recall = TruePositives / (TruePositives + FalseNegatives)\n",
        "recall = recall_score(labels_test, y_pred, average='binary')\n",
        "print('Recall: %.3f' % (recall*100))\n",
        "# F-Measure = (2 * Precision * Recall) / (Precision + Recall)\n",
        "# calculate score\n",
        "score = f1_score(labels_test, y_pred, average='binary')\n",
        "print('F-Measure: %.3f' % (score*100))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix: \n",
            "[[1488  511]\n",
            " [ 457 1128]]\n",
            "Accuracy: 72.991\n",
            "Precision: 68.822\n",
            "Recall: 71.167\n",
            "F-Measure: 69.975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7EDeFata22V",
        "colab_type": "code",
        "outputId": "d128b41e-4efa-4322-fc24-ec9160e7099e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/My Drive/Colab Notebooks/Signature Verification vgg16 model GDPS/model_vgg16_GDPS.h5')\n",
        "# Evaluate the model on the test data using `evaluate`\n",
        "print('\\n# Evaluate on test data')\n",
        "results = model.evaluate(validation_generator)\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# Evaluate on test data\n",
            "112/112 [==============================] - 17s 156ms/step\n",
            "test loss, test acc: [0.6362605094909668, 0.7020089030265808]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}